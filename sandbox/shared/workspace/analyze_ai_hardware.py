#!/usr/bin/env python3
"""
AIç¡¬ä»¶è¶‹åŠ¿åˆ†æè„šæœ¬
ç”¨äºåˆ†æAIèŠ¯ç‰‡æ€§èƒ½æ•°æ®å’Œç”ŸæˆæŠ¥å‘Š
"""

import csv
import json
from datetime import datetime

def read_csv_data(filepath):
    """è¯»å–CSVæ ¼å¼çš„AIç¡¬ä»¶æ•°æ®"""
    chips = []
    with open(filepath, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        for row in reader:
            chips.append(row)
    return chips

def analyze_performance_trends(chips):
    """åˆ†ææ€§èƒ½è¶‹åŠ¿"""
    analysis = {
        'cloud_chips': [],
        'edge_chips': [],
        'emerging_chips': [],
        'stats': {}
    }
    
    for chip in chips:
        category = chip['Category']
        
        # æå–æ€§èƒ½æ•°æ®
        try:
            if 'TFLOPS' in chip['Peak Performance']:
                perf = float(chip['Peak Performance'].split()[0])
            elif 'TOPS' in chip['Peak Performance']:
                perf = float(chip['Peak Performance'].split()[0])
            else:
                perf = 0
        except:
            perf = 0
            
        chip_data = {
            'model': chip['Chip Model'],
            'manufacturer': chip['Manufacturer'],
            'performance': perf,
            'power': chip['Power Consumption'],
            'process': chip['Process Node']
        }
        
        if category == 'Cloud AI':
            analysis['cloud_chips'].append(chip_data)
        elif category == 'Edge AI':
            analysis['edge_chips'].append(chip_data)
        elif category == 'Emerging':
            analysis['emerging_chips'].append(chip_data)
    
    # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    analysis['stats'] = {
        'total_chips': len(chips),
        'cloud_count': len(analysis['cloud_chips']),
        'edge_count': len(analysis['edge_chips']),
        'emerging_count': len(analysis['emerging_chips']),
        'analysis_date': datetime.now().strftime('%Y-%m-%d')
    }
    
    return analysis

def generate_recommendations(analysis):
    """ç”ŸæˆæŠ€æœ¯é€‰å‹å»ºè®®"""
    recommendations = []
    
    # äº‘ç«¯èŠ¯ç‰‡æ¨è
    cloud_perf = [(c['performance'], c['model'], c['manufacturer']) 
                  for c in analysis['cloud_chips'] if c['performance'] > 0]
    if cloud_perf:
        top_cloud = max(cloud_perf, key=lambda x: x[0])
        recommendations.append({
            'category': 'äº‘ç«¯è®­ç»ƒ',
            'recommendation': f"{top_cloud[1]} ({top_cloud[2]})",
            'reason': f"æœ€é«˜ç®—åŠ›: {top_cloud[0]} TFLOPS",
            'applications': 'å¤§è§„æ¨¡æ¨¡å‹è®­ç»ƒã€ç§‘å­¦è®¡ç®—'
        })
    
    # è¾¹ç¼˜èŠ¯ç‰‡æ¨èï¼ˆåŸºäºèƒ½æ•ˆï¼‰
    edge_chips = analysis['edge_chips']
    if edge_chips:
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è®¡ç®—èƒ½æ•ˆæ¯”
        recommendations.append({
            'category': 'è¾¹ç¼˜æ¨ç†',
            'recommendation': "Qualcomm AI 100 Pro / NVIDIA Jetsonç³»åˆ—",
            'reason': 'å¹³è¡¡ç®—åŠ›ã€åŠŸè€—å’Œç”Ÿæ€æ”¯æŒ',
            'applications': 'æ™ºèƒ½æ‰‹æœºã€æœºå™¨äººã€IoTè®¾å¤‡'
        })
    
    # æ–°å…´æŠ€æœ¯å…³æ³¨
    recommendations.append({
        'category': 'æ–°å…´æŠ€æœ¯',
        'recommendation': 'å­˜ç®—ä¸€ä½“ã€å…‰å­è®¡ç®—èŠ¯ç‰‡',
        'reason': 'èƒ½æ•ˆæ¯”æå‡10-100å€ï¼Œé•¿æœŸé¢ è¦†æ€§æŠ€æœ¯',
        'applications': 'ä¸“ç”¨åœºæ™¯ã€ä¸‹ä¸€ä»£è®¡ç®—æ¶æ„'
    })
    
    return recommendations

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("AIç¡¬ä»¶è¶‹åŠ¿åˆ†æç³»ç»Ÿ")
    print("=" * 60)
    
    # è¯»å–æ•°æ®
    try:
        chips = read_csv_data('ai_hardware_comparison_table.csv')
        print(f"âœ“ æˆåŠŸè¯»å– {len(chips)} æ¬¾AIèŠ¯ç‰‡æ•°æ®")
    except FileNotFoundError:
        print("âœ— æ•°æ®æ–‡ä»¶æœªæ‰¾åˆ°ï¼Œä½¿ç”¨ç¤ºä¾‹æ•°æ®")
        # è¿™é‡Œå¯ä»¥æ·»åŠ ç¤ºä¾‹æ•°æ®
        return
    
    # åˆ†æè¶‹åŠ¿
    analysis = analyze_performance_trends(chips)
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ•°æ®åˆ†æç»Ÿè®¡:")
    print(f"   æ€»è®¡èŠ¯ç‰‡: {analysis['stats']['total_chips']}")
    print(f"   äº‘ç«¯èŠ¯ç‰‡: {analysis['stats']['cloud_count']}")
    print(f"   è¾¹ç¼˜èŠ¯ç‰‡: {analysis['stats']['edge_count']}")
    print(f"   æ–°å…´æŠ€æœ¯: {analysis['stats']['emerging_count']}")
    
    # ç”Ÿæˆå»ºè®®
    recommendations = generate_recommendations(analysis)
    
    print(f"\nğŸ’¡ æŠ€æœ¯é€‰å‹å»ºè®®:")
    for i, rec in enumerate(recommendations, 1):
        print(f"\n  {i}. {rec['category']}:")
        print(f"     æ¨è: {rec['recommendation']}")
        print(f"     ç†ç”±: {rec['reason']}")
        print(f"     åº”ç”¨: {rec['applications']}")
    
    print(f"\nğŸ“ˆ å¸‚åœºè¶‹åŠ¿æ€»ç»“:")
    print("  1. äº‘ç«¯èŠ¯ç‰‡: 4nm/5nmåˆ¶ç¨‹ï¼Œç®—åŠ›å‘3000+ TFLOPSå‘å±•")
    print("  2. è¾¹ç¼˜èŠ¯ç‰‡: èƒ½æ•ˆæ¯”ä¼˜åŒ–ï¼ŒTOPS/Wattæˆä¸ºå…³é”®æŒ‡æ ‡")
    print("  3. æ–°å…´æŠ€æœ¯: å­˜ç®—ä¸€ä½“ã€å…‰å­è®¡ç®—çªç ´èƒ½æ•ˆç“¶é¢ˆ")
    print("  4. ä¸­å›½å‚å•†: åä¸ºã€å¯’æ­¦çºªç­‰åŠ é€Ÿå›½äº§æ›¿ä»£è¿›ç¨‹")
    
    print(f"\nâ° åˆ†æå®Œæˆæ—¶é—´: {analysis['stats']['analysis_date']}")
    print("=" * 60)
    
    # ä¿å­˜åˆ†æç»“æœ
    output = {
        'analysis': analysis,
        'recommendations': recommendations,
        'metadata': {
            'generated_at': analysis['stats']['analysis_date'],
            'version': '1.0'
        }
    }
    
    with open('ai_hardware_analysis.json', 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print("âœ“ åˆ†æç»“æœå·²ä¿å­˜åˆ°: ai_hardware_analysis.json")

if __name__ == '__main__':
    main()